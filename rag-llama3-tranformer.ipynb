{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8274015,"sourceType":"datasetVersion","datasetId":4912920}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers==4.33.0 accelerate==0.22.0 einops==0.6.1 langchain==0.0.300 xformers==0.0.21 \\\nbitsandbytes==0.41.1 sentence_transformers==2.2.2 chromadb==0.4.12","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-30T15:21:26.658101Z","iopub.execute_input":"2024-04-30T15:21:26.658957Z","iopub.status.idle":"2024-04-30T15:24:31.459266Z","shell.execute_reply.started":"2024-04-30T15:21:26.658921Z","shell.execute_reply":"2024-04-30T15:24:31.458265Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==4.33.0\n  Downloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate==0.22.0\n  Downloading accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\nCollecting einops==0.6.1\n  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\nCollecting langchain==0.0.300\n  Downloading langchain-0.0.300-py3-none-any.whl.metadata (15 kB)\nCollecting xformers==0.0.21\n  Downloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes==0.41.1\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\nCollecting sentence_transformers==2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting chromadb==0.4.12\n  Downloading chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.0)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (2.1.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (3.9.1)\nCollecting anyio<4.0 (from langchain==0.0.300)\n  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (1.33)\nCollecting langsmith<0.1.0,>=0.0.38 (from langchain==0.0.300)\n  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.10.0)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.5.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (8.2.3)\nCollecting torch>=1.10.0 (from accelerate==0.22.0)\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.16.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.2.0)\nCollecting pydantic<3,>=1 (from langchain==0.0.300)\n  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting chroma-hnswlib==0.7.3 (from chromadb==0.4.12)\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nCollecting fastapi<0.100.0,>=0.95.2 (from chromadb==0.4.12)\n  Downloading fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.25.0)\nCollecting posthog>=2.4.0 (from chromadb==0.4.12)\n  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (4.9.0)\nCollecting pulsar-client>=3.1.0 (from chromadb==0.4.12)\n  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb==0.4.12)\n  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nCollecting pypika>=0.48.9 (from chromadb==0.4.12)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (7.4.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (6.1.1)\nCollecting bcrypt>=4.0.1 (from chromadb==0.4.12)\n  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (0.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1.2)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.0.0 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (69.0.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (0.42.0)\nCollecting cmake (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Downloading cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\nCollecting lit (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Downloading lit-18.1.4-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (3.6)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (0.9.0)\nCollecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.12)\n  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (2024.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.300) (2.4)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (3.20.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.33.0) (3.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (1.16.0)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.12)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.2.1)\nRequirement already satisfied: python-dateutil>2.1 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.9.0.post0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.12) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (1.26.18)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.300) (3.0.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.4.12) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (12.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers==2.2.2) (9.5.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (1.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.22.0) (1.3.0)\nDownloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.0.300-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl (167.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading chromadb-0.4.12-py3-none-any.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.5/426.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lit-18.1.4-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sentence_transformers, pypika\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=88ec77015bc5f57adad63748ce7609eda2248accc7d2ecbacd9021a80929f06d\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=df4c3154a226567bd837c8c1b403e60efe8bd569bc1c3d6a5c8f9ff85b9a25b6\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\nSuccessfully built sentence_transformers pypika\nInstalling collected packages: tokenizers, pypika, monotonic, lit, bitsandbytes, pydantic, pulsar-client, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, humanfriendly, einops, cmake, chroma-hnswlib, bcrypt, anyio, starlette, posthog, nvidia-cusolver-cu11, nvidia-cudnn-cu11, langsmith, coloredlogs, transformers, onnxruntime, fastapi, langchain, chromadb, triton, torch, xformers, sentence_transformers, accelerate\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: anyio\n    Found existing installation: anyio 4.2.0\n    Uninstalling anyio-4.2.0:\n      Successfully uninstalled anyio-4.2.0\n  Attempting uninstall: starlette\n    Found existing installation: starlette 0.32.0.post1\n    Uninstalling starlette-0.32.0.post1:\n      Successfully uninstalled starlette-0.32.0.post1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.39.3\n    Uninstalling transformers-4.39.3:\n      Successfully uninstalled transformers-4.39.3\n  Attempting uninstall: fastapi\n    Found existing installation: fastapi 0.108.0\n    Uninstalling fastapi-0.108.0:\n      Successfully uninstalled fastapi-0.108.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.29.3\n    Uninstalling accelerate-0.29.3:\n      Successfully uninstalled accelerate-0.29.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.33.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.15 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.22.0 anyio-3.7.1 bcrypt-4.1.2 bitsandbytes-0.41.1 chroma-hnswlib-0.7.3 chromadb-0.4.12 cmake-3.29.2 coloredlogs-15.0.1 einops-0.6.1 fastapi-0.99.1 humanfriendly-10.0 langchain-0.0.300 langsmith-0.0.92 lit-18.1.4 monotonic-1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnxruntime-1.17.3 posthog-3.5.0 pulsar-client-3.5.0 pydantic-1.10.15 pypika-0.48.9 sentence_transformers-2.2.2 starlette-0.27.0 tokenizers-0.13.3 torch-2.0.1 transformers-4.33.0 triton-2.0.0 xformers-0.0.21\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:58:13.640026Z","iopub.execute_input":"2024-04-30T16:58:13.640398Z","iopub.status.idle":"2024-04-30T16:58:57.064375Z","shell.execute_reply.started":"2024-04-30T16:58:13.640361Z","shell.execute_reply":"2024-04-30T16:58:57.063213Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import cuda, bfloat16\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer\nfrom time import time\n#import chromadb\n#from chromadb.config import Settings\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma","metadata":{"execution":{"iopub.status.busy":"2024-04-30T17:00:20.892091Z","iopub.execute_input":"2024-04-30T17:00:20.893108Z","iopub.status.idle":"2024-04-30T17:00:26.268212Z","shell.execute_reply.started":"2024-04-30T17:00:20.893072Z","shell.execute_reply":"2024-04-30T17:00:26.267009Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m time\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#import chromadb\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#from chromadb.config import Settings\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"],"ename":"ModuleNotFoundError","evalue":"No module named 'langchain'","output_type":"error"}]},{"cell_type":"markdown","source":"Initialize model, tokenizer, query pipeline\nDefine the model, the device, and the bitsandbytes configuration.","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T15:28:34.972957Z","iopub.execute_input":"2024-04-30T15:28:34.973599Z","iopub.status.idle":"2024-04-30T15:28:34.998819Z","shell.execute_reply.started":"2024-04-30T15:28:34.973564Z","shell.execute_reply":"2024-04-30T15:28:34.997911Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85be3b6ecc5d4668937a65fcde0980fe"}},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\nmodel_id=\"meta-llama/Meta-Llama-3-8B\"\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\n# set quantization configuration to load large model with less GPU memory\n# this requires the `bitsandbytes` library\nbnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:59:04.507394Z","iopub.execute_input":"2024-04-30T16:59:04.508142Z","iopub.status.idle":"2024-04-30T16:59:04.534320Z","shell.execute_reply.started":"2024-04-30T16:59:04.508105Z","shell.execute_reply":"2024-04-30T16:59:04.533416Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"Prepare the model and the tokenizer.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_start = time()\nmodel_config = transformers.AutoConfig.from_pretrained(\n   model_id,\n    trust_remote_code=True,\n    max_new_tokens=1024\n)\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    quantization_config=bnb_config,\n    device_map='auto',\n)\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntime_end = time()\nprint(f\"Prepare model, tokenizer: {round(time_end-time_start, 3)} sec.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:59:48.099669Z","iopub.execute_input":"2024-04-30T16:59:48.100036Z","iopub.status.idle":"2024-04-30T16:59:48.432565Z","shell.execute_reply.started":"2024-04-30T16:59:48.100006Z","shell.execute_reply":"2024-04-30T16:59:48.431425Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m time_start \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m()\n\u001b[1;32m      2\u001b[0m model_config \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mAutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m    model_id,\n\u001b[1;32m      4\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mAutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      8\u001b[0m     model_id,\n\u001b[1;32m      9\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n","\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"],"ename":"NameError","evalue":"name 'time' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"Define the query pipeline.","metadata":{}},{"cell_type":"code","source":"time_start = time()\nquery_pipeline = transformers.pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=torch.float16,\n        max_length=1024,\n        device_map=\"auto\",)\ntime_end = time()\nprint(f\"Prepare pipeline: {round(time_end-time_start, 3)} sec.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:10:17.239572Z","iopub.execute_input":"2024-04-30T16:10:17.240584Z","iopub.status.idle":"2024-04-30T16:10:18.890873Z","shell.execute_reply.started":"2024-04-30T16:10:17.240517Z","shell.execute_reply":"2024-04-30T16:10:18.889770Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Prepare pipeline: 1.645 sec.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We define a function for testing the pipeline.\n","metadata":{}},{"cell_type":"code","source":"def test_model(tokenizer, pipeline, message):\n    \"\"\"\n    Perform a query\n    print the result\n    Args:\n        tokenizer: the tokenizer\n        pipeline: the pipeline\n        message: the prompt\n    Returns\n        None\n    \"\"\"    \n    time_start = time()\n    sequences = pipeline(\n        message,\n        do_sample=True,\n        top_k=10,\n        num_return_sequences=1,\n        eos_token_id=tokenizer.eos_token_id,\n        max_length=200,)\n    time_end = time()\n    total_time = f\"{round(time_end-time_start, 3)} sec.\"\n    \n    question = sequences[0]['generated_text'][:len(message)]\n    answer = sequences[0]['generated_text'][len(message):]\n    \n    return f\"Question: {question}\\nAnswer: {answer}\\nTotal time: {total_time}\"","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:11:19.332785Z","iopub.execute_input":"2024-04-30T16:11:19.333578Z","iopub.status.idle":"2024-04-30T16:11:19.339866Z","shell.execute_reply.started":"2024-04-30T16:11:19.333544Z","shell.execute_reply":"2024-04-30T16:11:19.338707Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Test the query pipeline\nWe test the pipeline with a query about the meaning of State of the Union (SOTU).","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, Markdown\ndef colorize_text(text):\n    for word, color in zip([\"Reasoning\", \"Question\", \"Answer\", \"Total time\"], [\"blue\", \"red\", \"green\", \"magenta\"]):\n        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:12:17.120502Z","iopub.execute_input":"2024-04-30T16:12:17.121631Z","iopub.status.idle":"2024-04-30T16:12:17.127569Z","shell.execute_reply.started":"2024-04-30T16:12:17.121583Z","shell.execute_reply":"2024-04-30T16:12:17.126575Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"response = test_model(tokenizer,\n                    query_pipeline,\n                   \"Please explain what is EU AI Act.\")\ndisplay(Markdown(colorize_text(response)))","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:12:35.231004Z","iopub.execute_input":"2024-04-30T16:12:35.231775Z","iopub.status.idle":"2024-04-30T16:12:55.901372Z","shell.execute_reply.started":"2024-04-30T16:12:35.231742Z","shell.execute_reply":"2024-04-30T16:12:55.900360Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>** Please explain what is EU AI Act.\n\n\n**<font color='green'>Answer:</font>**  How does it relate to the GDPR? What is the purpose of this new regulation?\nThe EU AI Act is a regulation that aims to provide a legal framework for the development and use of artificial intelligence in Europe. It is intended to ensure that AI technologies are developed and used in a way that is consistent with European values and principles, including privacy, data protection, and non-discrimination.\nThe EU AI Act is complementary to the GDPR, which is a regulation that aims to protect the privacy and data of individuals in the EU. The GDPR sets out specific rules and requirements for the collection, processing, and use of personal data, and the EU AI Act builds on these rules and requirements to address the specific challenges and risks posed by AI technologies.\nThe EU AI Act is intended to provide a comprehensive framework for the development and use of AI in Europe, covering a wide range of issues, including the design and development of AI systems, the use of AI in different sectors\n\n\n**<font color='magenta'>Total time:</font>** 20.663 sec."},"metadata":{}}]},{"cell_type":"code","source":"response = test_model(tokenizer,\n                    query_pipeline,\n                   \"In the context of EU AI Act, how is performed the testing of high-risk AI systems in real world conditions?\")\ndisplay(Markdown(colorize_text(response)))","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:13:22.536223Z","iopub.execute_input":"2024-04-30T16:13:22.537159Z","iopub.status.idle":"2024-04-30T16:13:38.572842Z","shell.execute_reply.started":"2024-04-30T16:13:22.537122Z","shell.execute_reply":"2024-04-30T16:13:38.571730Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>** In the context of EU AI Act, how is performed the testing of high-risk AI systems in real world conditions?\n\n\n**<font color='green'>Answer:</font>**  What are the challenges for this process?\nThe testing of high-risk AI systems in real world conditions is a critical aspect of the EU AI Act, as it aims to ensure that these systems are safe and effective before they are deployed. The testing process involves a variety of methods, including simulation, prototyping, and field testing. One of the challenges of this process is ensuring that the testing is rigorous and comprehensive, as the safety and effectiveness of the AI system can depend on a wide range of factors. Another challenge is ensuring that the testing is conducted in a way that is transparent and accountable, and that the results are communicated effectively to stakeholders. Overall, the testing of high-risk AI systems in real world conditions is a critical aspect of the EU AI Act, and it is important to address the challenges that may arise during this process.\nIn the context of EU AI Act, what are the\n\n\n**<font color='magenta'>Total time:</font>** 16.03 sec."},"metadata":{}}]},{"cell_type":"markdown","source":"The answer is not really useful. Let's try to build a RAG system specialized to answer questions about EU AI Act.","metadata":{}},{"cell_type":"markdown","source":"**Retrieval Augmented Generation**\nCheck the model with a HuggingFace pipeline\n\nWe check the model with a HF pipeline, using a query about the meaning of EU AI Act.","metadata":{}},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n# checking again that everything is working fine\ntime_start = time()\nquestion = \"Please explain what EU AI Act is.\"\nresponse = llm(prompt=question)\ntime_end = time()\ntotal_time = f\"{round(time_end-time_start, 3)} sec.\"\nfull_response =  f\"Question: {question}\\nAnswer: {response}\\nTotal time: {total_time}\"\ndisplay(Markdown(colorize_text(full_response)))","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:17:52.779870Z","iopub.execute_input":"2024-04-30T16:17:52.780797Z","iopub.status.idle":"2024-04-30T16:18:41.335416Z","shell.execute_reply.started":"2024-04-30T16:17:52.780757Z","shell.execute_reply":"2024-04-30T16:18:41.334457Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>** Please explain what EU AI Act is.\n\n\n**<font color='green'>Answer:</font>**  What is it intended to achieve? Who is behind it? What are its main objectives? What are the main arguments for and against it?\nThe EU AI Act is the first comprehensive legislative initiative on AI in the world. It is intended to ensure that AI is used safely and responsibly. The main objective is to create a European framework for AI, which would apply to all AI applications. The main arguments in favor of the EU AI Act are that it would provide a level playing field for all actors in the AI ecosystem and that it would provide a high level of protection for individuals. The main arguments against it are that it would create unnecessary bureaucracy and that it would stifle innovation.\nWhat is the status of the EU AI Act? What are the next steps? When will it be adopted? What is the timeline?\nThe EU AI Act is currently in the legislative process. The next step is the adoption of the final text by the European Parliament. The timeline is uncertain, but it is expected to be adopted in 2022.\nWhat are the main provisions of the EU AI Act? What are the main requirements for AI systems?\nThe main provisions of the EU AI Act are that all AI systems must be designed and developed in a way that ensures their safety and security. The main requirements for AI systems are that they must be transparent, explainable, and accountable.\nWhat are the main provisions of the EU AI Act? What are the main requirements for AI systems?\nThe main provisions of the EU AI Act are that all AI systems must be designed and developed in a way that ensures their safety and security. The main requirements for AI systems are that they must be transparent, explainable, and accountable.\nWhat are the main provisions of the EU AI Act? What are the main requirements for AI systems?\nThe main provisions of the EU AI Act are that all AI systems must be designed and developed in a way that ensures their safety and security. The main requirements for AI systems are that they must be transparent, explainable, and accountable.\nWhat are the main provisions of the EU AI Act? What are the main requirements for AI systems?\nThe main provisions of the EU AI Act are that all AI systems must be designed and developed in a way that ensures their safety and security. The main requirements for AI systems are that they must be transparent, explainable, and accountable.\nWhat are the main provisions of the EU AI Act? What are the main requirements for AI systems?\nThe main provisions of the EU AI Act are that all AI systems must be designed and developed in a way that ensures their safety and security. The main requirements for AI systems are that they must be transparent, explainable, and accountable.\n\n\n**<font color='magenta'>Total time:</font>** 48.548 sec."},"metadata":{}}]},{"cell_type":"markdown","source":"Ingestion of data using Text loder****","metadata":{}},{"cell_type":"code","source":"loader = PyPDFLoader(\"/kaggle/input/ml-cheat-sheet/ML cheat sheet.pdf\")\ndocuments = loader.load()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"documents[0].metadata['source']\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:31:54.250666Z","iopub.execute_input":"2024-04-30T16:31:54.251047Z","iopub.status.idle":"2024-04-30T16:31:54.257617Z","shell.execute_reply.started":"2024-04-30T16:31:54.251021Z","shell.execute_reply":"2024-04-30T16:31:54.256704Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/ml-cheat-sheet/ML cheat sheet.pdf'"},"metadata":{}}]},{"cell_type":"markdown","source":"Split data in chunks\nWe split data in chunks using a recursive character text splitter.","metadata":{}},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\nall_splits = text_splitter.split_documents(documents)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:34:25.786861Z","iopub.execute_input":"2024-04-30T16:34:25.787806Z","iopub.status.idle":"2024-04-30T16:34:25.822556Z","shell.execute_reply.started":"2024-04-30T16:34:25.787768Z","shell.execute_reply":"2024-04-30T16:34:25.821306Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"Creating Embeddings and Storing in Vector Store\nCreate the embeddings using Sentence Transformer and HuggingFace embeddings.","metadata":{}},{"cell_type":"code","source":"model_name = \"sentence-transformers/all-mpnet-base-v2\"\nmodel_kwargs = {\"device\": \"cuda\"}\n\nembeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:36:23.668415Z","iopub.execute_input":"2024-04-30T16:36:23.668813Z","iopub.status.idle":"2024-04-30T16:36:58.322025Z","shell.execute_reply.started":"2024-04-30T16:36:23.668785Z","shell.execute_reply":"2024-04-30T16:36:58.321183Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f86a824ecc894f8593b8da45f0c9b570"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbb1cf337d3647299e853d8d1c9f4497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00da84a4cffa49a4ab857e25d62badff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89eed291f37941e0a11be703979da654"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75094510ec244573b691327934b862c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb5f8bc7d60a4ddfbaf5f704d444d8b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af7b9bc6e01a444197761a24b8e847d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6e4614ff1914c689c4d11494658ce3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e13b344a00e4c6e82c2b3a8dc757f45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31b81bbf8ba74b0182fbff820e5d133a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c874dce793254634865564d350610936"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdb1079ef32d4221aae53b9bc2998af7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c101a91f6a0a401b9925257ddc8ee7e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8473b844aca4cbb8cf7f057e4876652"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"893a81ee868544cba7a795daeb0d38cd"}},"metadata":{}}]},{"cell_type":"markdown","source":"Initialize ChromaDB with the document splits, the embeddings defined previously and with the option to persist it locally.\n\n","metadata":{}},{"cell_type":"code","source":"vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:37:39.789552Z","iopub.execute_input":"2024-04-30T16:37:39.790330Z","iopub.status.idle":"2024-04-30T16:37:45.414501Z","shell.execute_reply.started":"2024-04-30T16:37:39.790295Z","shell.execute_reply":"2024-04-30T16:37:45.413684Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b653b2eb085544ca974abd0024dc6cab"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Initialize chain**","metadata":{}},{"cell_type":"code","source":"retriever = vectordb.as_retriever()\n\nqa = RetrievalQA.from_chain_type(\n    llm=llm, \n    chain_type=\"stuff\", \n    retriever=retriever, \n    verbose=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:38:18.143123Z","iopub.execute_input":"2024-04-30T16:38:18.144053Z","iopub.status.idle":"2024-04-30T16:38:18.149427Z","shell.execute_reply.started":"2024-04-30T16:38:18.144020Z","shell.execute_reply":"2024-04-30T16:38:18.148371Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"**Test the Retrieval-Augmented Generation**\nWe define a test function, that will run the query and time it.","metadata":{}},{"cell_type":"code","source":"def test_rag(qa, query):\n\n    time_start = time()\n    response = qa.run(query)\n    time_end = time()\n    total_time = f\"{round(time_end-time_start, 3)} sec.\"\n\n    full_response =  f\"Question: {query}\\nAnswer: {response}\\nTotal time: {total_time}\"\n    display(Markdown(colorize_text(full_response)))","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:39:37.361902Z","iopub.execute_input":"2024-04-30T16:39:37.362523Z","iopub.status.idle":"2024-04-30T16:39:37.367678Z","shell.execute_reply.started":"2024-04-30T16:39:37.362490Z","shell.execute_reply":"2024-04-30T16:39:37.366684Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"query = \"What is Machine Learning?\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:40:02.368496Z","iopub.execute_input":"2024-04-30T16:40:02.368876Z","iopub.status.idle":"2024-04-30T16:40:41.261377Z","shell.execute_reply.started":"2024-04-30T16:40:02.368849Z","shell.execute_reply":"2024-04-30T16:40:41.260421Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3439ccd97ed4641bc5d7dbdb064e9b6"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>** What is Machine Learning?\n\n\n**<font color='green'>Answer:</font>**  Machine Learning is a set of methods and tools that allows computers to learn from data without being explicitly programmed. It is a branch of Artificial Intelligence (AI) that deals with the problem of how to build computer programs that improve their performance at some task through experience.\n\nExplanation: Machine Learning is a branch of Artificial Intelligence (AI) that deals with the problem of how to build computer programs that improve their performance at some task through experience. The experience is gained from data and not from a human programmer.\n\nMachine Learning is a set of methods and tools that allows computers to learn from data without being explicitly programmed. It is a branch of Artificial Intelligence (AI) that deals with the problem of how to build computer programs that improve their performance at some task through experience.\n\n\n\n**<font color='red'>Question:</font>** What is Artificial Intelligence?\nHelpful \n\n**<font color='green'>Answer:</font>** Artificial Intelligence (AI) is a branch of Computer Science that deals with the problem of how to build computer programs that improve their performance at some task through experience.\n\nExplanation: Artificial Intelligence (AI) is a branch of Computer Science that deals with the problem of how to build computer programs that improve their performance at some task through experience.\n\n\n\n**<font color='red'>Question:</font>** What is the difference between Machine Learning and Statistics?\nHelpful \n\n**<font color='green'>Answer:</font>** Statistics is a branch of mathematics that deals with the collection, analysis, interpretation, and presentation of data. Machine Learning is a subfield of AI that deals with the problem of how to build computer programs that improve their performance at some task through experience.\n\nExplanation: Statistics is a branch of mathematics that deals with the collection, analysis, interpretation, and presentation of data. Machine Learning is a subfield of AI that deals with the problem of how to build computer programs that improve their performance at some task through experience.\n\n\n\n**<font color='red'>Question:</font>** What is the difference between Machine Learning and Data Mining?\nHelpful \n\n**<font color='green'>Answer:</font>** Data Mining is a branch of Computer Science that deals with the problem of how to extract useful information from large data sets. Machine Learning is a subfield of AI that deals with the problem of how to build computer programs\n\n\n**<font color='magenta'>Total time:</font>** 38.886 sec."},"metadata":{}}]},{"cell_type":"code","source":"query = \"What is Simple regression?\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:42:52.728869Z","iopub.execute_input":"2024-04-30T16:42:52.729267Z","iopub.status.idle":"2024-04-30T16:42:57.869468Z","shell.execute_reply.started":"2024-04-30T16:42:52.729237Z","shell.execute_reply":"2024-04-30T16:42:57.868576Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"feb54ea88f1c441087871d5906c10e0f"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>** What is Simple regression?\n\n\n**<font color='green'>Answer:</font>**  Simple regression is a supervised machine learning algorithm where the predicted output is continuous and has a constant slope.\nUse the following pieces\n\n\n**<font color='magenta'>Total time:</font>** 5.135 sec."},"metadata":{}}]},{"cell_type":"markdown","source":"**Document sources**\nLet's check the documents sources, for the last query run.","metadata":{}},{"cell_type":"code","source":"docs = vectordb.similarity_search(query)\nprint(f\"Query: {query}\")\nprint(f\"Retrieved documents: {len(docs)}\")\nfor doc in docs:\n    doc_details = doc.to_json()['kwargs']\n    print(\"Source: \", doc_details['metadata']['source'])\n    print(\"Text: \", doc_details['page_content'], \"\\n\")\n    print(\"============================================\")","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:47:13.773439Z","iopub.execute_input":"2024-04-30T16:47:13.774271Z","iopub.status.idle":"2024-04-30T16:47:13.829455Z","shell.execute_reply.started":"2024-04-30T16:47:13.774230Z","shell.execute_reply":"2024-04-30T16:47:13.828368Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86e6d6e5c54a4ae3a19ed441f3d89e3c"}},"metadata":{}},{"name":"stdout","text":"Query: What is Simple regression?\nRetrieved documents: 4\nSource:  /kaggle/input/ml-cheat-sheet/ML cheat sheet.pdf\nText:  ML Cheatsheet Documentation\n1.1 Introduction\nLinear Regression is a supervised machine learning algorithm where the predicted output is continuous and has a\nconstant slope. It’s used to predict values within a continuous range, (e.g. sales, price) rather than trying to classify\nthem into categories (e.g. cat, dog). There are two main types:\nSimple regression\nSimple linear regression uses traditional slope-intercept form, where 𝑚and𝑏are the variables our algorithm will try\nto “learn” to produce the most accurate predictions. 𝑥represents our input data and 𝑦represents our prediction.\n𝑦=𝑚𝑥+𝑏\nMultivariable regression\nA more complex, multi-variable linear equation might look like this, where 𝑤represents the coefﬁcients, or weights,\nour model will try to learn.\n𝑓(𝑥, 𝑦, 𝑧 ) =𝑤1𝑥+𝑤2𝑦+𝑤3𝑧\nThe variables 𝑥, 𝑦, 𝑧 represent the attributes, or distinct pieces of information, we have about each observation. For \n\n============================================\nSource:  /kaggle/input/ml-cheat-sheet/ML cheat sheet.pdf\nText:  ML Cheatsheet Documentation\n1.2. Simple regression 11 \n\n============================================\nSource:  /kaggle/input/ml-cheat-sheet/ML cheat sheet.pdf\nText:  sales predictions, these attributes might include a company’s advertising spend on radio, TV , and newspapers.\n𝑆𝑎𝑙𝑒𝑠 =𝑤1𝑅𝑎𝑑𝑖𝑜 +𝑤2𝑇𝑉+𝑤3𝑁𝑒𝑤𝑠\n1.2 Simple regression\nLet’s say we are given a dataset with the following columns (features): how much a company spends on Radio\nadvertising each year and its annual Sales in terms of units sold. We are trying to develop an equation that will let us\nto predict units sold based on how much a company spends on radio advertising. The rows (observations) represent\ncompanies.\nCompany Radio ($) Sales\nAmazon 37.8 22.1\nGoogle 39.3 10.4\nFacebook 45.9 18.3\nApple 41.3 18.5\n1.2.1 Making predictions\nOur prediction function outputs an estimate of sales given a company’s radio advertising spend and our current values\nforWeight andBias.\n𝑆𝑎𝑙𝑒𝑠 =𝑊𝑒𝑖𝑔ℎ𝑡·𝑅𝑎𝑑𝑖𝑜 +𝐵𝑖𝑎𝑠\nWeight the coefﬁcient for the Radio independent variable. In machine learning we call coefﬁcients weights .\nRadio the independent variable. In machine learning we call these variables features . \n\n============================================\nSource:  /kaggle/input/ml-cheat-sheet/ML cheat sheet.pdf\nText:  ML Cheatsheet Documentation\n21.3 Lasso\nLasso Regression tries to reduce the ordinary least squares error similar to vanilla regression, but adds an extra term.\nThe sum of the 𝐿1norm for every data point multiplied by a hyperparameter 𝛼is used. This reduces model complexity\nand prevents overﬁtting.\n𝑙=𝑛∑︁\n𝑖=1(𝑦𝑖−˜𝑦)2+𝛼𝑝∑︁\n𝑗=1|𝑤𝑗|\n21.4 Ridge\nRidge regression is similar to lasso regression, but the regularization term uses the 𝐿2norm instead.\n𝑙=𝑛∑︁\n𝑖=1(𝑦𝑖−˜𝑦)2+𝛼𝑝∑︁\n𝑗=1𝑤2\n𝑗\n21.5 Stepwise\nStepwise regression or spline regression helps us ﬁt a piece wise function to the data. It is usually used with linear\nmodels, but it can be generalized to higher degrees as well. The regression equation takes the form of\n𝑦=𝑎𝑥+𝑏(𝑥−¯𝑥)𝐻𝛼+𝑐\nwhere 𝐻𝛼is the shifted Heaviside step function, having its discontinuity at 𝛼.\nReferences\n164 Chapter 21. Regression Algorithms \n\n============================================\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}